
# Stats Wire
# Pyspark_2
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName("Spark").getOrCreate()

# Pyspark_3
from datetime import date, datetime
from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType, TimestampType, FloatType
rdds = spark.sparkContext.parallelize([("Country", 1), ("Name", 2), ("Age", 3)])
print(rdds)
print(rdds.collect())

# Pyspark_4
rdd = spark.sparkContext.parallelize([
    (1, 1.0, 'string1', date(2021,1,1), datetime(2021,1,12,0)),
    (2, 2.0, 'string2', date(2021, 1, 2), datetime(2021, 1, 2, 12, 0)),
    (3, 3.0, 'string3', date(2021, 3, 1), datetime(2021, 1, 3, 12, 0))
])

schema = StructType([
    StructField('num', IntegerType(), True),
    StructField('float', FloatType(), True),
    StructField('string', StringType(), True),
    StructField('date', DateType(), True),
    StructField('datetime', TimestampType(), True)
])
df = spark.createDataFrame(rdd, schema=schema)
df.show()

# Pyspark_6
spark = SparkSession.builder.appName("spark").getOrCreate()
df = spark.read.csv(r"C:\Users\user\Downloads\iris.csv", header=True)

df.show(5)
df.printSchema()
df.select('species').distinct().show()

# Pyspark_7
# read_json

spark = SparkSession.builder.appName("spark").getOrCreate()

df = spark.read.option("mode", "PERMISSIVE").json(r"C:\\Users\\user\\Downloads\\sample1.json")
df.show()

df_txt = spark.read.option("header", "True").option("delimiter", "\t").csv(r"C:\Users\user\Downloads\iris_tab.txt")
df_txt.show(5)
